{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOrIhk8bixFWaOf87WJFA+B",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arjilham17/62-explore-pygame/blob/main/Sesi6Preprosessing_KomenIG.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UGfSSWlJINVy",
        "outputId": "2a537072-c391-40e5-ef89-a9a1b4c43493"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk) (8.2.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk) (1.5.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from nltk) (4.67.1)\n",
            "Collecting Sastrawi\n",
            "  Downloading Sastrawi-1.0.1-py2.py3-none-any.whl.metadata (909 bytes)\n",
            "Downloading Sastrawi-1.0.1-py2.py3-none-any.whl (209 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.7/209.7 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: Sastrawi\n",
            "Successfully installed Sastrawi-1.0.1\n",
            "Collecting emoji\n",
            "  Downloading emoji-2.14.1-py3-none-any.whl.metadata (5.7 kB)\n",
            "Downloading emoji-2.14.1-py3-none-any.whl (590 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m590.6/590.6 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: emoji\n",
            "Successfully installed emoji-2.14.1\n"
          ]
        }
      ],
      "source": [
        "!pip install nltk\n",
        "!pip install Sastrawi\n",
        "!pip install emoji"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import emoji\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
        "import nltk\n",
        "\n"
      ],
      "metadata": {
        "id": "F--4AyPbKFuj"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Membaca data dari file CSV\n",
        "df = pd.read_csv('instagram.csv')\n",
        "\n",
        "# Menampilkan data awal\n",
        "print(\"Data Awal:\")\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_SDEwjCpKI3A",
        "outputId": "05c47d3c-f487-4b2c-d6a0-1fe2899cc9bd"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data Awal:\n",
            "           username                                           komentar\n",
            "0         kompascom  KOREKSI: Dalam infografis tertulis “Periode su...\n",
            "1      noto.aries.3  Pdip dukung anies aja, agar bisa menang jadi s...\n",
            "2     fakta.jakarta  Kok respondennya cuma 400 orang min? 😂 Di akun...\n",
            "3    annie_anieeeee                           Tetep Ahok ❤️❤️❤️❤️🔥🔥🔥🔥🔥\n",
            "4  info___rumahbaru                        ahok aja daripada si mANIES\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fungsi untuk menghapus emoji\n",
        "def remove_emoji(text):\n",
        "    if isinstance(text, str):  # Check if the text is a string before processing\n",
        "        return emoji.replace_emoji(text, replace='')\n",
        "    else:\n",
        "        return text  # Return the original value if it's not a string\n",
        "\n",
        "# Fungsi untuk membersihkan teks\n",
        "def clean_text(text):\n",
        "    # Menghapus emoji\n",
        "    text = remove_emoji(text)\n",
        "    # Mengubah ke huruf kecil\n",
        "    if isinstance(text, str):  # Check if the text is a string before processing\n",
        "        text = text.lower()\n",
        "        # Menghapus username, hashtag, dan link\n",
        "        text = re.sub(r'@\\w+|#\\w+|http\\S+', '', text)\n",
        "        # Menghapus angka dan tanda baca kecuali huruf\n",
        "        text = re.sub(r'[^a-z\\s]', '', text)\n",
        "        # Menghapus spasi ekstra\n",
        "        text = re.sub(r'\\s+', ' ', text).strip()\n",
        "    return text\n",
        "\n",
        "# Mengaplikasikan fungsi clean_text ke kolom 'comment'\n",
        "df['cleaned_comment'] = df['komentar'].apply(clean_text)\n",
        "\n",
        "# Menampilkan data yang sudah dibersihkan\n",
        "print(\"\\nData Setelah Pembersihan:\")\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YXrqUGv4KSWZ",
        "outputId": "16ee6df2-9d4c-43ef-b19f-bbda3e98c709"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Data Setelah Pembersihan:\n",
            "           username                                           komentar  \\\n",
            "0         kompascom  KOREKSI: Dalam infografis tertulis “Periode su...   \n",
            "1      noto.aries.3  Pdip dukung anies aja, agar bisa menang jadi s...   \n",
            "2     fakta.jakarta  Kok respondennya cuma 400 orang min? 😂 Di akun...   \n",
            "3    annie_anieeeee                           Tetep Ahok ❤️❤️❤️❤️🔥🔥🔥🔥🔥   \n",
            "4  info___rumahbaru                        ahok aja daripada si mANIES   \n",
            "\n",
            "                                     cleaned_comment  \n",
            "0  koreksi dalam infografis tertulis periode surv...  \n",
            "1  pdip dukung anies aja agar bisa menang jadi sa...  \n",
            "2  kok respondennya cuma orang min di akun kami p...  \n",
            "3                                         tetep ahok  \n",
            "4                        ahok aja daripada si manies  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Menyimpan data yang sudah diproses ke file baru\n",
        "df.to_csv('bersih1.csv', index=False)"
      ],
      "metadata": {
        "id": "-TdyByyGKelq"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mengunduh stopwords dan tokenizer\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Menghapus stop words\n",
        "stop_words = set(stopwords.words('indonesian'))  # Gunakan stopwords bahasa Indonesia\n",
        "df['cleaned_comment'] = df['cleaned_comment'].apply(\n",
        "    lambda x: ' '.join([word for word in word_tokenize(x) if word not in stop_words]) if isinstance(x, str) else x\n",
        ")\n",
        "\n",
        "# Menampilkan data setelah penghapusan stop words\n",
        "print(\"\\nData Setelah Penghapusan Stop Words:\")\n",
        "print(df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GGeJnB_OLFxM",
        "outputId": "81b945d0-c6a2-4bc8-cbcd-0a0dc2b5b0ec"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Data Setelah Penghapusan Stop Words:\n",
            "           username                                           komentar  \\\n",
            "0         kompascom  KOREKSI: Dalam infografis tertulis “Periode su...   \n",
            "1      noto.aries.3  Pdip dukung anies aja, agar bisa menang jadi s...   \n",
            "2     fakta.jakarta  Kok respondennya cuma 400 orang min? 😂 Di akun...   \n",
            "3    annie_anieeeee                           Tetep Ahok ❤️❤️❤️❤️🔥🔥🔥🔥🔥   \n",
            "4  info___rumahbaru                        ahok aja daripada si mANIES   \n",
            "\n",
            "                                     cleaned_comment  \n",
            "0  koreksi infografis tertulis periode survei jul...  \n",
            "1  pdip dukung anies aja menang sakit hati pilpre...  \n",
            "2  respondennya orang min akun polling ribu respo...  \n",
            "3                                         tetep ahok  \n",
            "4                                 ahok aja si manies  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Membuat objek stemmer\n",
        "factory = StemmerFactory()\n",
        "stemmer = factory.create_stemmer()\n",
        "\n",
        "# Proses stemming\n",
        "df['stemmed_comment'] = df['cleaned_comment'].apply(\n",
        "    lambda x: stemmer.stem(x) if isinstance(x, str) else ''\n",
        ")\n",
        "\n",
        "# Menampilkan data setelah stemming\n",
        "print(\"\\nData Setelah Stemming:\")\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PAyB0rYVMDKI",
        "outputId": "213ed7b1-5399-4655-da08-cec529e0799c"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Data Setelah Stemming:\n",
            "           username                                           komentar  \\\n",
            "0         kompascom  KOREKSI: Dalam infografis tertulis “Periode su...   \n",
            "1      noto.aries.3  Pdip dukung anies aja, agar bisa menang jadi s...   \n",
            "2     fakta.jakarta  Kok respondennya cuma 400 orang min? 😂 Di akun...   \n",
            "3    annie_anieeeee                           Tetep Ahok ❤️❤️❤️❤️🔥🔥🔥🔥🔥   \n",
            "4  info___rumahbaru                        ahok aja daripada si mANIES   \n",
            "\n",
            "                                     cleaned_comment  \\\n",
            "0  koreksi infografis tertulis periode survei jul...   \n",
            "1  pdip dukung anies aja menang sakit hati pilpre...   \n",
            "2  respondennya orang min akun polling ribu respo...   \n",
            "3                                         tetep ahok   \n",
            "4                                 ahok aja si manies   \n",
            "\n",
            "                                     stemmed_comment  \n",
            "0  koreksi infografis tulis periode survei juli p...  \n",
            "1  pdip dukung anies aja menang sakit hati pilpre...  \n",
            "2  responden orang min akun polling ribu responde...  \n",
            "3                                         tetep ahok  \n",
            "4                                 ahok aja si manies  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenisasi\n",
        "df['tokens'] = df['stemmed_comment'].apply(\n",
        "    lambda x: word_tokenize(x) if isinstance(x, str) else []\n",
        ")\n",
        "\n",
        "# Menampilkan data setelah tokenisasi\n",
        "print(\"\\nData Setelah Tokenisasi:\")\n",
        "print(df.head())\n",
        "\n",
        "# Menyimpan data yang sudah diproses ke file baru\n",
        "df.to_csv('processed_instagram_comments.csv', index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CVwVU7wsMjJe",
        "outputId": "763d9df3-6110-4372-b1d6-8ee90a692747"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Data Setelah Tokenisasi:\n",
            "           username                                           komentar  \\\n",
            "0         kompascom  KOREKSI: Dalam infografis tertulis “Periode su...   \n",
            "1      noto.aries.3  Pdip dukung anies aja, agar bisa menang jadi s...   \n",
            "2     fakta.jakarta  Kok respondennya cuma 400 orang min? 😂 Di akun...   \n",
            "3    annie_anieeeee                           Tetep Ahok ❤️❤️❤️❤️🔥🔥🔥🔥🔥   \n",
            "4  info___rumahbaru                        ahok aja daripada si mANIES   \n",
            "\n",
            "                                     cleaned_comment  \\\n",
            "0  koreksi infografis tertulis periode survei jul...   \n",
            "1  pdip dukung anies aja menang sakit hati pilpre...   \n",
            "2  respondennya orang min akun polling ribu respo...   \n",
            "3                                         tetep ahok   \n",
            "4                                 ahok aja si manies   \n",
            "\n",
            "                                     stemmed_comment  \\\n",
            "0  koreksi infografis tulis periode survei juli p...   \n",
            "1  pdip dukung anies aja menang sakit hati pilpre...   \n",
            "2  responden orang min akun polling ribu responde...   \n",
            "3                                         tetep ahok   \n",
            "4                                 ahok aja si manies   \n",
            "\n",
            "                                              tokens  \n",
            "0  [koreksi, infografis, tulis, periode, survei, ...  \n",
            "1  [pdip, dukung, anies, aja, menang, sakit, hati...  \n",
            "2  [responden, orang, min, akun, polling, ribu, r...  \n",
            "3                                      [tetep, ahok]  \n",
            "4                            [ahok, aja, si, manies]  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Misalkan kita menggunakan kolom 'cleaned_comment' sebagai fitur\n",
        "X = df['cleaned_comment']\n",
        "\n",
        "# Memisahkan data menjadi train dan test set\n",
        "X_train, X_test = train_test_split(X, test_size=0.2, random_state=42)\n",
        "\n",
        "# Menampilkan ukuran setiap subset\n",
        "print(f\"Train set size: {X_train.shape[0]}\")\n",
        "print(f\"Test set size: {X_test.shape[0]}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rmSgq55gMwJF",
        "outputId": "521504b4-3e3f-4dd5-e20b-755cfeb9186a"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train set size: 329\n",
            "Test set size: 83\n"
          ]
        }
      ]
    }
  ]
}